library(jtools)
View(Credit)
Cred <- Credit %>%
select(Balance, Limit, Income)
head(Cred)
glimpse(Cred)
Cred %>% skim()
###correlation between variables
Cred %>% cor()
###correlation between each variable
Cred %>% cor()
###the correlation between each variable to Balance variable
ggplot(Cred, aes(Limit, Balance)) + geom_point() + labs(x = "Credit Limit in $", y = "Credit Balance in $", title = "Relationship between balance and credit limit")
###the correlation between each variable to Balance variable
ggplot(Cred, aes(Limit, Balance)) + geom_point() + labs(x = "Credit Limit in $", y = "Credit Balance in $", title = "Relationship between balance and credit limit") + geom_smooth(method = "lm", se = FALSE)
ggplot(Cred, des(Income, Balance)) + geom_point() + labs(x = "Income in $1000", y = "Credit Balance in $", title = "Relationship between balance and income") + geom_smooth(method = "lm", se = FALSE)
ggplot(Cred, aes(Income, Balance)) + geom_point() + labs(x = "Income in $1000", y = "Credit Balance in $", title = "Relationship between balance and income") + geom_smooth(method = "lm", se = FALSE)
###plotting all variables
plot_ly(Cred, x = ~Income, y = ~Limit, z = ~Balance, type = "scatter3d", mode = "markers")
###fitting the model
Balance_Model <- lm(Balance ~ Limit + Income, data = Cred)
###get the fitted value. but we have to define the model first
regression_points <- get_regression_points(model)
regression_points
summary(Balance_Model)
###get the fitted values
fitted_values_Balance <- get_regression_table(Balance_Model)
fitted_values_Balance
###Showing all parameters estimation
parameter_estimate <- get_regression_table(Balance_Model)
parameter_estimate
###get the fitted values
fitted_values <- get_regression_points(Balance_Model)
fitted_values
###checking the assumptions --> mean of residuals are zero
ggplot(fitted_values, aes(Limit, residual)) + geom_point() + labs(x = "Limit Credit in $", y = "Residuals", title = "Limit Credit vs Residual") + geom_hline(yintercept = 0, col="red", size = 2)
ggplot(fitted_values, aes(Income, residual)) + geom_point() + labs(x = "Income in $1000", y = "Residuals", title = "Income vs Residual") + geom_hline(yintercept = 0, col="yellow", size = 2)
###checking the asssumptions --> the residuals are normally distributed
ggplot(fitted_values, aes(residual)) + geom_histogram(binwidth = 40, col = "blue") + labs(x = "Residuals")
##############MULTIPLE LINEAR REGRESSION - ONE CONTINOUS AND ONE CATEGORICAL VARIABLE##############
evals_score_age_gender <- evals %>%
select(score, age, gender)
evals_score_age_gender %>% skim()
glimpse(evals_score_age_gender)
###correlation between variables
evals_score_age_gender %>% get_correlation(formula = score ~ age)
evals.score %>% get_correlation(formula = score ~ bty_avg)
###correlation between each variable
Cred %>% cor()
evals_score_age_gender %>% cor()
###the correlation between each variable to outcome variable by plot
ggplot(evals_score_age_gender, aes(age, score, col = gender)) + geom_jitter() + labs(x = "Age", y = "Teaching Score", col = "Gender") + geom_smooth(method = "lm", se = FALSE)
###the correlation between each variable to outcome variable by plot
ggplot(evals_score_age_gender, aes(x = age, y = score, col = gender)) + geom_jitter() + labs(x = "Age", y = "Teaching Score", col = "Gender") + geom_smooth(method = "lm", se = FALSE)
###the correlation between each variable to outcome variable by plot
ggplot(evals_score_age_gender, aes(x = age, y = score, col = gender)) + geom_jitter() + labs(x = "Age", y = "Teaching Score", col = "Gender") + geom_smooth(method = "lm", se = FALSE)
###the correlation between each variable to outcome variable by plot
ggplot(evals_score_age_gender, aes(x = age, y = score, col = gender)) + geom_jitter() + labs(x = "Age", y = "Teaching Score", col = "Gender") + geom_smooth(method = "lm", se = FALSE)
###fitting the model
model_2covariates <- lm(score ~ age + gender, data = evals_score_age_gender)
model_2covariates
###Showing all parameters estimation
get_regression_table(model_2covariates)
###Superimpose our parallel regression lines onto the scatterplot of teaching score against age
coeff <- model_2covariates %>% coef() %>% as.numeric()
coeff
slopes <- evals_score_age_gender %>%
group_by(gender) %>%
summarise(minimum_age = min(age), maximum_age = max(age)) %>%
mutate(intercept = coeff[1]) %>%
mutate(intercept = ifelse(gender == "male", intercept + coeff[3], intercept)) %>%
gather(point, age, -c(gender, intercept))%>%
mutate(y_hat = intercept + age * coeff[2])
slopes
slopes <- evals_score_age_gender %>%
group_by(gender) %>%
summarise(minimum_age = min(age), maximum_age = max(age)) %>%
mutate(intercept = coeff[1]) %>%
mutate(intercept = ifelse(gender == "male", intercept + coeff[3], intercept)) %>%
gather(point, age, -c(gender, intercept))%>%
mutate(y_hat = intercept + age * coeff[2])
View(evals_score_age_gender)
ggplot(evals_score_age_gender, aes(age, score, col = gender)) + geom_jitter() + labs(x = "Age", y = "Teaching Score", col = "Gender") + geom_line(slopes, aes(y_hat), size = 2)
ggplot(evals_score_age_gender, aes(x = age, y = score, col = gender)) + geom_jitter() + labs(x = "Age", y = "Teaching Score", col = "Gender") + geom_line(slopes, aes(y = y_hat), size = 2)
ggplot(evals_score_age_gender, aes(x = age, y = score, col = gender)) + geom_jitter() + labs(x = "Age", y = "Teaching Score", col = "Gender") + geom_line(data = slopes, aes(y = y_hat), size = 2)
slopes
###mutilpe regression model with interaction among covariate variables
multiple_regres <- lm(score ~ age*gender, data = evals_score_age_gender)
###summary of the variables
get_regression_table(multiple_regres)
###get the different slopes (different from the previous case)
ggplot(evals_score_age_gender, aes(x= age, y = score, col=gender)) + geom_jitter() + labs(x = "Age", y = "Score", col = "Gender") + geom_smooth(method = "lm", se = FALSE)
###the correlation between each variable to outcome variable by plot
ggplot(evals_score_age_gender, aes(x = age, y = score, col = gender)) + geom_jitter() + labs(x = "Age", y = "Teaching Score", col = "Gender") + geom_smooth(method = "lm", se = FALSE)
###get fitted values
fitted_values_multiple <- get_regression_points(multiple_regres)
fitted_values_multiple
###assumption the residuals againts the covariate variables by gender
ggplot(data = fitted_values_multiple, aes(x = age, y = residual)) + geom_point() + labs(x = "Age", y = "Residuals", title = "Residual vs Age by Gender") + geom_line(yintercept = 0, col = "red", size = 2) + facet_wrap(~gender)
###assumption the residuals againts the covariate variables by gender
ggplot(data = fitted_values_multiple, aes(x = age, y = residual)) + geom_point() + labs(x = "Age", y = "Residuals", title = "Residual vs Age by Gender") + geom_hline(yintercept = 0, col = "red", size = 2) + facet_wrap(~gender)
exp(-2.61131)
exp(-1.12216)
exp(-2.32917)
exp(-0.03330)
#'
#'  ## Loading R library
#' Firstly, let's load up the library and the data used in Lab 1.
par(ask=FALSE)
library('fda')
load("all.RData")
data(CanadianWeather)
temp = CanadianWeather$dailyAv[,,1]
precip = CanadianWeather$dailyAv[,,2]
daytime = (1:365)-0.5
day5 = seq(0,365,5)
dayrng = c(0,365)
fbasis =  create.fourier.basis(dayrng,65)
harmLfd = vec2Lfd(c(0,(2*pi/365)^2,0),rangeval=dayrng)
temp.fdPar = fdPar(fbasis,harmLfd,1e-2)
tempSmooth = smooth.basis(daytime,temp,temp.fdPar)
tempfd = tempSmooth$fd
annualprec = log10( apply(precip,2,mean))
xlist = list(len=2)
xlist[[1]] = rep(1,35)
xlist[[2]] = tempfd
bwtlist = list(len=2)
cbasis = create.constant.basis(dayrng)
bwtlist[[1]] = fdPar(cbasis)
beta.fdPar = fdPar(fbasis,harmLfd,10^12.5)
prec.model = fRegress(annualprec,xlist,bwtlist)
names(prec.model)
prec.model$betaestlist[[1]]$fd$coef
prec.model = fRegress(annualprec,xlist,bwtlist)
bwtlist[[2]] = beta.fdPar
prec.model = fRegress(annualprec,xlist,bwtlist)
annualprec = log10( apply(precip,2,mean))
annualprec
tempfd
annualprec
View(annualprec)
xlist = list(len=2)
View(xlist)
xlist[[1]] = rep(1,35)
xlist[[2]] = tempfd
View(xlist)
bwtlist = list(len=2)
View(bwtlist)
cbasis = create.constant.basis(dayrng)
bwtlist[[1]] = fdPar(cbasis)
View(bwtlist)
bwtlist[[1]] = fdPar(cbasis)
beta.fdPar = fdPar(fbasis,harmLfd,10^12.5)
bwtlist[[2]] = beta.fdPar
View(beta.fdPar)
prec.model = fRegress(annualprec,xlist,bwtlist)
names(prec.model)
prec.model$betaestlist[[1]]$fd$coef
plot(prec.model$betaestlist[[2]])
lambdas = 10^(seq(5,15,0.5))
ocvs = rep(0,length(lambdas))
View(lambdas)
length(lambdas)
for(ilam in 1:length(lambdas)){
bwtlisti = bwtlist                # define temporary beta.fdPar and bwtlist
beta.fdPari = beta.fdPar
beta.fdPari$lambda = lambdas[ilam]   # update lambda
bwtlisti[[2]] = beta.fdPari
prec.modeli = fRegress(annualprec,xlist,bwtlisti)
ocvs[ilam] = prec.modeli$OCV        # record ocv
}
lambdas = 10^(seq(5,15,0.5))
View(lambdas)
length(lambdas)
ocvs = rep(0,length(lambdas))
for(ilam in 1:length(lambdas)){
bwtlisti = bwtlist                # define temporary beta.fdPar and bwtlist
beta.fdPari = beta.fdPar
beta.fdPari$lambda = lambdas[ilam]   # update lambda
bwtlisti[[2]] = beta.fdPari
prec.modeli = fRegress(annualprec,xlist,bwtlisti)
ocvs[ilam] = prec.modeli$OCV        # record ocv
}
plot(lambdas,ocvs,type='b',log='x')
prec.model$df
yhat = prec.model$yhatfdobj
plot(yhat,annualprec)
abline(c(0,1))
sigma = sum( (annualprec-yhat)^2 )/(35-prec.model$df)
sigma = sum( (annualprec-yhat)^2 )/(35-prec.model$df)
sigma
sigmaE = sigma*diag(35)
prec.stderr = fRegress.stderr(prec.model,NULL,sigmaE)
betahat = prec.model$betaestlist[[2]]
betastd = prec.stderr$betastderrlist[[2]]
# Chunk 1
library(gt)
library(dplyr)
library(ggplot2)
library(gmodels)
library(car)
library(AER)
library(MASS)
# Chunk 2
tab = function(df, var1, var2){
CrossTable(df[, var1], df[, var2],
prop.r = T,
prop.c = F,
prop.t = F,
prop.chisq = F,
dnn = c(var1, var2))
}
# Chunk 3
data <- read.csv('dataset20.csv', stringsAsFactors = FALSE)
setwd("~/Documents/UofG/Data Analysis Skill/Group Project 2/Git/DAS-Groupt20")
# Chunk 1
library(gt)
library(dplyr)
library(ggplot2)
library(gmodels)
library(car)
library(AER)
library(MASS)
# Chunk 2
tab = function(df, var1, var2){
CrossTable(df[, var1], df[, var2],
prop.r = T,
prop.c = F,
prop.t = F,
prop.chisq = F,
dnn = c(var1, var2))
}
# Chunk 3
data <- read.csv('dataset20.csv', stringsAsFactors = FALSE)
sum(is.na(data))
colnames(data) <- c('type', 'month', 'year', 'intake', 'outcome', 'chip', 'duration')
# Chunk 4: tbl-desc
#| label: tbl-desc
#| tbl-cap: The Description of the Dataset
#| tbl-align: center
desc_var <- c('The type of animal admitted to the shelter',
'Month the animal was admitted',
'Year the animal was admitted',
'Reason for the animal being admitted',
'Final outcome for the admitted animal',
'Did the animal have a microchip with owner information',
'Days spent at the shelter between being admitted and the final outcome')
tbl <- cbind(colnames(data), desc_var)
colnames(tbl) <- c('Variable', 'Description')
knitr::kable(tbl)
# Chunk 5
char_vars <- sapply(data, is.character)
data[char_vars] <- lapply(data[char_vars], function(x) {
factor(x)
})
str(data)
# Chunk 6: fig-duration
#| label: fig-duration
#| fig-cap: The Distribution of the Duration Variable
#| fig-align: center
ggplot(data, aes(x=duration)) +
geom_histogram(binwidth=1, fill='blue', color='black')
# Chunk 7
Q1 <- quantile(data$duration, 0.25)
Q3 <- quantile(data$duration, 0.75)
IQR <- Q3 - Q1
upper <- Q3 + 1.5 * IQR
out <- which(data$duration > upper)
med <- median(data$duration)
data$duration[out] <- med
# Chunk 8: fig-month
#| label: fig-month
#| fig-cap: The Distribution of Month vs Duration Variable
#| fig-align: center
ggplot(data, aes(x=month,y=duration, group=month))+
geom_boxplot(aes(fill=month))
# Chunk 9: fig-year
#| label: fig-year
#| fig-cap: The Distribution of Year vs Duration Variable
#| fig-align: center
ggplot(data, aes(x=year,y=duration, group=year))+
geom_boxplot(aes(fill=year))
# Chunk 10: tbl-type
#| label: tbl-type
#| tbl-cap: The Distribution of Animal Types
#| tbl-align: center
knitr::kable(prop.table(table(data$type)))
data <- data %>%
filter(!(type == "BIRD" | type == "WILDLIFE")) %>%
droplevels()
# Chunk 11: fig-intake
#| label: fig-intake
#| fig-cap: The Distribution of the Intake Variable
#| fig-align: center
ggplot(data, aes(y=duration, x=intake, group=intake))+
geom_boxplot(aes(fill=intake))+
theme(legend.position = "none")
# Chunk 12
replace <- function(data, variable, category) {
Q1 <- quantile(data[[variable]][data$intake==category], 0.25)
Q3 <- quantile(data[[variable]][data$intake==category], 0.75)
IQR <- Q3 - Q1
upper <- Q3 + 1.5 * IQR
out <- which(data$intake==category & data[[variable]] > upper)
med <- median(data[[variable]][data$intake==category])
data[[variable]][out] <- med
return(data)
}
categories <- unique(data$intake)
for(cat in categories) {
data <- replace(data, 'duration', cat)
}
# Chunk 13: fig-outcome
#| label: fig-outcome
#| fig-cap: The Distribution of the Outcome Variable
#| fig-align: center
ggplot(data, aes(y=duration, x=outcome, group=outcome))+
geom_boxplot(aes(fill=outcome))+
theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1), plot.margin = margin(5.5, 20, 5.5, 5.5, "pt"))
# Chunk 14
replace2 <- function(data, variable, category) {
Q1 <- quantile(data[[variable]][data$outcome == category], 0.25)
Q3 <- quantile(data[[variable]][data$outcome == category], 0.75)
IQR <- Q3 - Q1
upper <- Q3 + 1.5 * IQR
out <- which(data$outcome == category & data[[variable]] > upper)
med <- median(data[[variable]][data$outcome == category])
data[[variable]][out] <- med
return(data)
}
categories <- unique(data$outcome)
for(cat in categories) {
data <- replace2(data, 'duration', cat)
}
# Chunk 15: fig-chip
#| label: fig-chip
#| fig-cap: The Distribution of Chip Variable
ggplot(data, aes(y=duration, x=chip, group=chip))+
geom_boxplot(aes(fill=chip))+
theme(legend.position = "none")
# Chunk 16
replace3 <- function(data, variable, category) {
Q1 <- quantile(data[[variable]][data$chip == category], 0.25)
Q3 <- quantile(data[[variable]][data$chip == category], 0.75)
IQR <- Q3 - Q1
upper <- Q3 + 1.5 * IQR
out <- which(data$chip == category & data[[variable]] > upper)
med <- median(data[[variable]][data$chip == category])
data[[variable]][out] <- med
return(data)
}
categories <- unique(data$chip)
for(cat in categories) {
data <- replace3(data, 'duration', cat)
}
# Chunk 17: tbl-chisquare
#| label: tbl-chisquare
#| tbl-cap: Chi-Square Test Results for Association with Duration of Shelter Stay
pvalues <- data.frame(
Variable = c("type", "intake", "outcome", "chip"),
P_Value = c(
chisq.test(data$type, data$duration)$p.value,
chisq.test(data$intake, data$duration)$p.value,
chisq.test(data$outcome, data$duration)$p.value,
chisq.test(data$chip, data$duration)$p.value
)
)
knitr::kable(pvalues)
# Chunk 18: tbl-gvif
#| label: tbl-gvif
#| tbl-cap: Multicollinearity Assessment of Predictor Variables
model <- lm(duration~., data = data)
knitr::kable(vif(model))
# Chunk 19
data <- subset(data, select = -month)
data <- subset(data, select = -year)
glm_poisson <- glm(duration~., family = "poisson", data = data)
summary(glm_poisson)
# Chunk 20
dispersiontest(glm_poisson)
# 2.584389
# Chunk 21: fig-resid
#| label: fig-resid
#| fig-cap: Analysis of Overdispersion in Poisson Regression Model
#| fig-align: center
#| fig-width: 4
#| fig-height: 3
ggplot(glm_poisson, aes(x = log(fitted(glm_poisson)), y = log((data$duration - fitted(glm_poisson))^2))) + geom_point(col = "#DD7A65") + geom_abline(slope = 1, intercept = 0, col = "#F58B05", size = 1) + ylab(expression((y-hat(mu))^2)) + xlab(expression(hat(mu)))
# Chunk 22: fig-residanalysis1
#| fig-cap: Residuals vs Fitted Values
#| label: fig-residanalysis1
#| fig-align: center
#| fig-width: 4
#| fig-height: 3
plot(glm_poisson$fitted.values, residuals(glm_poisson, type = "deviance"),
xlab = "Fitted Values", ylab = "Deviance Residuals", pch = 20)
abline(h = 0, col = "red")
# Chunk 23: fig-residanalysis2
#| fig-cap: Scale-Location
#| label: fig-residanalysis2
#| fig-align: center
#| fig-width: 4
#| fig-height: 3
plot(glm_poisson$fitted.values, sqrt(abs(residuals(glm_poisson, type = "pearson"))), xlab = "Fitted Values", ylab = "√|Standardized Pearson Residuals|")
# Chunk 24: fig-residanalysis3
#| fig-cap: Residuals vs Leverage
#| label: fig-residanalysis3
#| fig-align: center
#| fig-width: 4
#| fig-height: 3
plot(hatvalues(glm_poisson), residuals(glm_poisson, type = "pearson"), xlab = "Leverage", ylab = "Pearson Residuals")
abline(h = 0, col = "red")
# Chunk 25
glm_nb <- glm.nb(duration~., data = data)
summary(glm_nb)
# Chunk 26: fig-BN1
#| fig-cap: Residuals vs Fitted Values
#| label: fig-BN1
#| fig-align: center
#| fig-width: 4
#| fig-height: 3
par(mfrow = c(1,1))
plot(glm_nb, which = 1)
# Chunk 27: fig-BN2
#| fig-cap: Normal Q-Q Plot
#| label: fig-BN2
#| fig-align: center
#| fig-width: 4
#| fig-height: 3
par(mfrow = c(1,1))
plot(glm_nb, which = 2)
# Chunk 28: fig-BN3
#| fig-cap: Scale-Location
#| label: fig-BN3
#| fig-align: center
#| fig-width: 4
#| fig-height: 3
par(mfrow = c(1,1))
plot(glm_nb, which = 3)
# Chunk 29: fig-BN4
#| fig-cap: Residuals vs Leverage
#| label: fig-BN4
#| fig-align: center
#| fig-width: 4
#| fig-height: 3
par(mfrow = c(1,1))
plot(glm_nb, which = 4)
# Chunk 30
glm_poisson_optimal <- stepAIC(glm_poisson, direction = "backward")
glm_nb_optimal <- stepAIC(glm_nb, direction = "backward")
dispersiontest(glm_poisson)
# 2.584389
setwd("~/Documents/UofG/Data Mining and Machine Learning/Group Project")
19950*250
# Chunk 1
library(gt)
library(dplyr)
library(ggplot2)
library(gmodels)
library(car)
library(AER)
library(MASS)
# Chunk 2
tab = function(df, var1, var2){
CrossTable(df[, var1], df[, var2],
prop.r = T,
prop.c = F,
prop.t = F,
prop.chisq = F,
dnn = c(var1, var2))
}
# Chunk 3
data <- read.csv('dataset20.csv', stringsAsFactors = FALSE)
setwd("~/Documents/UofG/projectbeenmade/projectbeenmade/Group Project - Data Mining and Machine Learning")
#| echo: false
#| warning: false
# Read CSV from data dir
data <- read_csv("dataset.csv")
setwd("~/Documents/UofG/projectbeenmade/projectbeenmade/Group Project - Data Mining and Machine Learning")
#| echo: false
#| warning: false
# Read CSV from data dir
data <- read_csv("dataset.csv")
#| echo: false
#| warning: false
# Import Libraries
library(tidyverse)
library(tidyr)
library(gt)
library(skimr)
library(knitr)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(GGally)
library(caret)
library(Boruta)
library(rpart)
library(rpart.plot)
library(MLmetrics)
library(randomForest)
library(class)
library(MASS)
library(e1071)
library(smotefamily)
library(cvms)
library(tibble)
library(Boruta)
#| echo: false
#| warning: false
# Read CSV from data dir
data <- read_csv("dataset.csv")
